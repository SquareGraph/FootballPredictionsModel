{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjiUVjAogDacOylWtpxiGP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is the model comparsion notebook. \n",
        "We will cover a bunch of models with a baseline data from a English Premier League, to distingiush potential and next steps.\n",
        "\n",
        "The main reasoning behind this research is to create the algobetting robot. Whilst mode odds on home wins and distribution are around 1,16(distribution: ~43%), away wins 1,78(dist: ~34%) and draws 3,38(dist: ~23%), it means that:\n",
        "(1,16*0,43+1,78*0,34+3,38*0,23) * accuracy of prediction should set a baseline for a ROI of this robot.\n",
        "\n",
        "And math is very clear here: "
      ],
      "metadata": {
        "id": "zDKCLpfq4vw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_odds = 1.16*0.43+1.78*0.34+3.38*0.23\n",
        "print(f\"The sum of odds in one season, if we type everything correct is: {round(sum_of_odds, 3)}\")\n",
        "print(f\"So to have non negative ROI (not counting any commisions on money transfer), our algorithms accuracy must be accurate {round(1/sum_of_odds*100, 4)}% times.\")\n",
        "\n",
        "## data based on EPL season of 2021"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPyuK3BT9oFy",
        "outputId": "35c9ff87-afbd-47c6-de68-068d401b0353"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of odds in one season, if we type everything correct is: 1.881\n",
            "So to have non negative ROI (not counting any commisions on money transfer), our algorithms accuracy must be accurate 53.1519% times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So we'll be covering following algorithms:\n",
        "\n",
        "1. SKlearn RandomForestClassifier (no need of explanation)\n",
        "2. XGBoost Classifier (no need of explanation)\n",
        "3. PyTorch TabNet implementationby Dreamquark-ai:\n",
        "  <br>  a) https://github.com/dreamquark-ai/tabnet - official docs of PyTorch implementation of the original algorithm\n",
        "  <br>  b) https://arxiv.org/abs/1908.07442 - official research papers of TabNet\n",
        "<br> c) https://www.geeksforgeeks.org/tabnet/ - a quick guide over the TabNet\n",
        "\n",
        "4. DeepInisght with DeppInsight like architecture:\n",
        "  <br>  a) DeepInsight paper: https://www.nature.com/articles/s41598-019-47765-6 - a methodology of converting tabular data to Images, article in Nature with some data\n",
        " <br>   b) https://github.com/nicomignoni/tab2img - a documentation of the implemenation of DeepInsight in a python library \n",
        "<br>    c) Disclaimer: this is a baseline approach, so I decided just to implement the one leg of proposed net. "
      ],
      "metadata": {
        "id": "0Zko6mWV2NEz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OZY18-Dxf-n",
        "outputId": "2042221f-51ce-4ecf-cfbd-ec42eec60531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Let's start from importing and mounting drive, cause we'll be working on a dataset prepared before in a following notebook:\n",
        "# Notebook for Data Gathering https://github.com/SquareGraph/FootballPredictionsModel/blob/main/DataGathering_from_Soccerdata.ipynb\n",
        "from IPython.utils.text import Path\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths declaration\n",
        "path = Path('/content/drive/MyDrive/Github/FootballPredictionsModel')\n",
        "data = 'data'"
      ],
      "metadata": {
        "id": "N3-66_OYxsmj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some standard imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xalMDBvdy8i9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main = pd.read_csv(path/data/\"with_fifa_raw.csv\") ; print(main.shape) # We have a lot of features here, 141!\n",
        "main.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "fHkRL1dEzVOm",
        "outputId": "8d784f67-b694-4c13-f0e4-181e70f0191f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(380, 141)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0               date_x       home_team                away_team  \\\n",
              "0           0  2021-08-13 00:00:00       Brentford                  Arsenal   \n",
              "1           1  2021-08-14 00:00:00         Burnley   Brighton & Hove Albion   \n",
              "2           2  2021-08-14 00:00:00         Chelsea           Crystal Palace   \n",
              "3           3  2021-08-14 00:00:00         Everton              Southampton   \n",
              "4           4  2021-08-14 00:00:00  Leicester City  Wolverhampton Wanderers   \n",
              "\n",
              "    game_id    Goal_x  Off Target_x  Saved_x  Woodwork_x  <10_x  ...  \\\n",
              "0  3adf2aa7  1.500000           2.8     1.00         0.0    3.6  ...   \n",
              "1  4eb36e37  1.000000           2.6     2.00         0.0    2.2  ...   \n",
              "2  6f454493  1.400000           4.0     4.25         0.0    3.8  ...   \n",
              "3  c99ebbf5  1.666667           4.0     2.00         0.0    3.0  ...   \n",
              "4  0b346a62  1.000000           3.6     2.50         0.0    3.0  ...   \n",
              "\n",
              "         33        34        35        36        37        38        39  \\\n",
              "0 -2.757576  0.393939 -0.333333 -3.060606 -1.636364 -2.242424 -2.060606   \n",
              "1  1.060606  2.666667  0.212121  0.181818 -0.030303  0.333333  0.212121   \n",
              "2  5.939394  3.787879  4.636363  5.151515  0.000000  1.484849  1.454546   \n",
              "3  6.636363  3.484849  1.878788  1.636364  0.181818  0.848485  0.363636   \n",
              "4  3.939394  3.545454  4.060606  3.151515  4.393940  3.545454  4.121212   \n",
              "\n",
              "         40        41        42  \n",
              "0 -1.484849 -0.545455 -1.424242  \n",
              "1  0.484849 -0.454545  0.363636  \n",
              "2  0.151515 -0.636364 -1.666667  \n",
              "3  0.484849  0.424242  0.515151  \n",
              "4  3.454546  4.878788  2.636364  \n",
              "\n",
              "[5 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55feb825-7c49-4b5a-9624-dbbb75b894d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date_x</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>game_id</th>\n",
              "      <th>Goal_x</th>\n",
              "      <th>Off Target_x</th>\n",
              "      <th>Saved_x</th>\n",
              "      <th>Woodwork_x</th>\n",
              "      <th>&lt;10_x</th>\n",
              "      <th>...</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2021-08-13 00:00:00</td>\n",
              "      <td>Brentford</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>3adf2aa7</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.757576</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-3.060606</td>\n",
              "      <td>-1.636364</td>\n",
              "      <td>-2.242424</td>\n",
              "      <td>-2.060606</td>\n",
              "      <td>-1.484849</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-1.424242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-08-14 00:00:00</td>\n",
              "      <td>Burnley</td>\n",
              "      <td>Brighton &amp; Hove Albion</td>\n",
              "      <td>4eb36e37</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.060606</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>-0.030303</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.484849</td>\n",
              "      <td>-0.454545</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-08-14 00:00:00</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>Crystal Palace</td>\n",
              "      <td>6f454493</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>...</td>\n",
              "      <td>5.939394</td>\n",
              "      <td>3.787879</td>\n",
              "      <td>4.636363</td>\n",
              "      <td>5.151515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.484849</td>\n",
              "      <td>1.454546</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-08-14 00:00:00</td>\n",
              "      <td>Everton</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>c99ebbf5</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.636363</td>\n",
              "      <td>3.484849</td>\n",
              "      <td>1.878788</td>\n",
              "      <td>1.636364</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.484849</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.515151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-08-14 00:00:00</td>\n",
              "      <td>Leicester City</td>\n",
              "      <td>Wolverhampton Wanderers</td>\n",
              "      <td>0b346a62</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.939394</td>\n",
              "      <td>3.545454</td>\n",
              "      <td>4.060606</td>\n",
              "      <td>3.151515</td>\n",
              "      <td>4.393940</td>\n",
              "      <td>3.545454</td>\n",
              "      <td>4.121212</td>\n",
              "      <td>3.454546</td>\n",
              "      <td>4.878788</td>\n",
              "      <td>2.636364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55feb825-7c49-4b5a-9624-dbbb75b894d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55feb825-7c49-4b5a-9624-dbbb75b894d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55feb825-7c49-4b5a-9624-dbbb75b894d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list(main.columns)"
      ],
      "metadata": {
        "id": "H2g19SNWDJcs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main.dtypes[main.dtypes == \"object\"] # And here all non-numerical categories. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcljOL5ATiLc",
        "outputId": "5f058012-e4c0-4e8e-80e7-c58169b91ed3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date_x       object\n",
              "home_team    object\n",
              "away_team    object\n",
              "game_id      object\n",
              "date_y       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What to do with those features.\n",
        "A Quick explanation:\n",
        "\n",
        "1. Object data types:\n",
        "   <br>a) We want to drop date_x and date_y features (as it seems not relevant to the game performance, without an information about additional games from other competition, and potential fatigue). From domain knowledge, raw date of a game it's a rubbish data I strongly believe.\n",
        "    <br> b) Home_team and away_team - assign each team a number, and treat them like every other numerical data. There's some logic behind this reasoning. Explain further in the document.\n",
        "    <br> c) game_id - absolutely unnecessary.\n",
        "\n",
        "2.  Numerical data types to drop from the features:\n",
        "\n",
        "    a) FTR - those are our Y values. We want to drop them before assining to the X values.\n",
        "   <br> b) D_HT, home_point,draw_points,away_points - A lost remains of some computation did during that processing. Absolutely to drop.\n",
        "  <br>  c) Unnamed: 0 - index like, probably effect of merging without droping index params. Drop.\n",
        "\n",
        "3. Numerical data types - Legend\n",
        "   <br> a) Columns named from 0 to 42: it's a SoFifa mean params, substracted between home and away.\n",
        "  <br>  b) home_rank, away_rank - ELO Rank at the day of a game\n",
        "  <br> c) all duplicated columns - rolling average (5 games window) for each team performance\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnvDhN32DSTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Team name transofmration\n",
        "\n",
        "Probably the team name may also affect the game result. For example if you are playing against strong rival your mental approach may vary from challenging the weaker one. So let's translate team names into integer values from 1 to 20."
      ],
      "metadata": {
        "id": "vxXgMVyHdlWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "team_integers = dict(zip(np.unique(main.home_team.to_numpy()),np.arange(1,21))) #dict from zip from unique team names labeled by the np arange.\n",
        "main.replace(team_integers, inplace=True) #replace all through dictionary method."
      ],
      "metadata": {
        "id": "ibtNhBF9eEct"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Raw, unnormalized data for initial baseline training.\n",
        "\n",
        "We want to start with a baseline models just from the raw data.\n",
        "But let's also check if time series character vary training or not. So we will build two different datasets. One that will be randomly splited, and the second one that takes first 80% of games for a training dataset and predict on the last 20%. Let's call them X_ts,y_ts for timeserieswise variation, and X_rand, y_rand for randomly splitted."
      ],
      "metadata": {
        "id": "quOjyOqmdZD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_dropped = main.drop([\"date_x\",\"date_y\",\"game_id\",\"Unnamed: 0\",\"D_HT\",\"home_point\",\"draw_points\",\"away_points\"],axis=1) # we are dropping all columns mentioned above"
      ],
      "metadata": {
        "id": "KcDtBEu1zys1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = main_dropped.FTR.to_numpy() #labels\n",
        "X = main_dropped.drop([\"FTR\"],axis=1).fillna(0).to_numpy() ## all nan comes from the effect of calculating rolling average (division by 0 at some point) or no records, so filling with 0 is not a bad idea."
      ],
      "metadata": {
        "id": "cl_r0j2-TtuD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## We will use our own train test split, because want to keep chronological order as those are time series data.\n",
        "\n",
        "def train_test_split_ts(features, targets, train_size=0.8):\n",
        "\n",
        "    \"\"\"Returns two tuples of Train and test sests, in X,y order.\"\"\"\n",
        "\n",
        "    TRAIN_SIZE = int(features.shape[0]*train_size)\n",
        "    X_ts_train, y_ts_train = features[:TRAIN_SIZE], targets[:TRAIN_SIZE]\n",
        "    X_ts_test, y_ts_test = features[TRAIN_SIZE:], targets[TRAIN_SIZE:]\n",
        "\n",
        "\n",
        "\n",
        "    return (X_ts_train, y_ts_train), (X_ts_test, y_ts_test)"
      ],
      "metadata": {
        "id": "TVtby4-ST7jW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ts, test_ts = train_test_split_ts(X,y) # split into tuples"
      ],
      "metadata": {
        "id": "1l1Q5C-qUeBu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unpack tuples for all other models\n",
        "X_train_ts, y_train_ts = train_ts \n",
        "X_test_ts, y_test_ts = test_ts"
      ],
      "metadata": {
        "id": "5SH-TL7RbjXp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First model RandomForestClassifier from sklearn\n",
        "We starts with a RandomForest for our absolute baseline."
      ],
      "metadata": {
        "id": "hMAQ-3bEjZzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "-teZvf9NjhHc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)"
      ],
      "metadata": {
        "id": "fVdmG5QajqGe"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train_ts, y_train_ts) # train the baseline model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsLAWK01j271",
        "outputId": "7d27f19e-c797-4709-f2e2-155e0a656171"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_split=10, n_estimators=50, random_state=1)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_preds = np.argmax(rf.predict_proba(X_test_ts), axis=1) # make prediction and call the argmax to have an index of the highest probability"
      ],
      "metadata": {
        "id": "PwHHWFSspvO0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_acc = accuracy_score(y_test_ts, rf_preds) ; rf_acc#np.sum((preds == y_test_ts).astype(float))/preds.shape[0] ; accuracy # calculate the model accuracy."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCtdNQRbp8Ic",
        "outputId": "bc59794f-bc5c-4a58-dec3-0a8f68cb1612"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5394736842105263"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_odds(x):\n",
        "\n",
        "    \"\"\"helper function to collect Avg odds per our prediction. To apply on a DataFrame\"\"\"\n",
        "\n",
        "    if x.FTR == 0:\n",
        "        return x.AvgH\n",
        "    elif x.FTR == 1:\n",
        "        return x.AvgA\n",
        "    elif x.FTR == 2:\n",
        "        return x.AvgD"
      ],
      "metadata": {
        "id": "skHM2S_xsckh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check the bookmakers odds score\n",
        "\n",
        "def check_score(main_df: pd.core.frame.DataFrame, predictions: np.array):\n",
        "    \n",
        "    \"\"\"A simple function that returns the DataFrame of correct results and a score\"\"\"\n",
        "\n",
        "    main_df[\"predictions\"] = 0\n",
        "    main_df.predictions[304:] = predictions\n",
        "\n",
        "    comparsion_of_predictions = main_df[[\"FTR\",\"predictions\",\"AvgH\",\"AvgA\",\"AvgD\"]][304:]\n",
        "    filter = comparsion_of_predictions.FTR == comparsion_of_predictions.predictions\n",
        "\n",
        "    filtered = comparsion_of_predictions[filter] \n",
        "    filtered[\"score_odds\"] = filtered.apply(lambda x: check_odds(x), axis=1)\n",
        "    score = filtered.sum(axis=0)[\"score_odds\"]\n",
        "\n",
        "    return filtered, score\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "ApyJrwBQtM35"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_rf, score_rf = check_score(main, rf_preds) ; score_rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2prYupCwxLHY",
        "outputId": "ff3afbb5-c876-415a-ae7b-f263076766d8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.39999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_odds_per_bet_rf = compare_rf.describe().loc[\"mean\"][\"score_odds\"] ; avg_odds_per_bet_rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itjoFKyP2pWO",
        "outputId": "5937185a-b2f6-49ff-c44b-20d7541e71b0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7902439024390242"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForestClassifier\n",
        "\n",
        "So our accuracy is over the target (nearly 54%) but it looks like investing 1 dollar per each game of the last 76 game wouldn't be the best idea in the world, cause our return was 73,4 dollars. But still better then random, as we have only 33% chances of good bet!"
      ],
      "metadata": {
        "id": "dWrVxUpuL9Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost - Baseline model 2"
      ],
      "metadata": {
        "id": "SdxWeFiB_bcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "Fdv8BCK7xWGx"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb_ = xgb.XGBClassifier(learning_rate=0.1,\n",
        "                              max_depth=5,\n",
        "                              n_estimators=100,\n",
        "                              subsample=0.5,\n",
        "                              colsample_bytree=0.5,\n",
        "                              eval_metric='mlogloss',\n",
        "                              verbosity=1) #Hyperparams\n",
        "\n",
        "\n",
        "\n",
        "model_xgb_.fit(X_train_ts, y_train_ts, early_stopping_rounds=100, eval_set=[(X_test_ts, y_test_ts)], verbose=True) #train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrCNyagmza8d",
        "outputId": "3df2d6d9-ef18-425e-977b-34384d20fe5c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.07159\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[1]\tvalidation_0-mlogloss:1.05318\n",
            "[2]\tvalidation_0-mlogloss:1.04096\n",
            "[3]\tvalidation_0-mlogloss:1.01734\n",
            "[4]\tvalidation_0-mlogloss:1.00851\n",
            "[5]\tvalidation_0-mlogloss:0.993597\n",
            "[6]\tvalidation_0-mlogloss:0.988864\n",
            "[7]\tvalidation_0-mlogloss:0.981035\n",
            "[8]\tvalidation_0-mlogloss:0.980294\n",
            "[9]\tvalidation_0-mlogloss:0.975226\n",
            "[10]\tvalidation_0-mlogloss:0.973907\n",
            "[11]\tvalidation_0-mlogloss:0.969354\n",
            "[12]\tvalidation_0-mlogloss:0.971531\n",
            "[13]\tvalidation_0-mlogloss:0.96034\n",
            "[14]\tvalidation_0-mlogloss:0.951886\n",
            "[15]\tvalidation_0-mlogloss:0.949096\n",
            "[16]\tvalidation_0-mlogloss:0.942552\n",
            "[17]\tvalidation_0-mlogloss:0.944439\n",
            "[18]\tvalidation_0-mlogloss:0.945999\n",
            "[19]\tvalidation_0-mlogloss:0.941998\n",
            "[20]\tvalidation_0-mlogloss:0.950489\n",
            "[21]\tvalidation_0-mlogloss:0.95129\n",
            "[22]\tvalidation_0-mlogloss:0.956154\n",
            "[23]\tvalidation_0-mlogloss:0.955074\n",
            "[24]\tvalidation_0-mlogloss:0.954337\n",
            "[25]\tvalidation_0-mlogloss:0.951503\n",
            "[26]\tvalidation_0-mlogloss:0.951399\n",
            "[27]\tvalidation_0-mlogloss:0.953565\n",
            "[28]\tvalidation_0-mlogloss:0.953836\n",
            "[29]\tvalidation_0-mlogloss:0.955758\n",
            "[30]\tvalidation_0-mlogloss:0.957268\n",
            "[31]\tvalidation_0-mlogloss:0.958729\n",
            "[32]\tvalidation_0-mlogloss:0.961163\n",
            "[33]\tvalidation_0-mlogloss:0.968318\n",
            "[34]\tvalidation_0-mlogloss:0.967337\n",
            "[35]\tvalidation_0-mlogloss:0.967885\n",
            "[36]\tvalidation_0-mlogloss:0.967632\n",
            "[37]\tvalidation_0-mlogloss:0.965485\n",
            "[38]\tvalidation_0-mlogloss:0.964648\n",
            "[39]\tvalidation_0-mlogloss:0.967449\n",
            "[40]\tvalidation_0-mlogloss:0.967415\n",
            "[41]\tvalidation_0-mlogloss:0.960743\n",
            "[42]\tvalidation_0-mlogloss:0.964174\n",
            "[43]\tvalidation_0-mlogloss:0.964877\n",
            "[44]\tvalidation_0-mlogloss:0.960568\n",
            "[45]\tvalidation_0-mlogloss:0.960386\n",
            "[46]\tvalidation_0-mlogloss:0.962454\n",
            "[47]\tvalidation_0-mlogloss:0.960242\n",
            "[48]\tvalidation_0-mlogloss:0.963387\n",
            "[49]\tvalidation_0-mlogloss:0.96631\n",
            "[50]\tvalidation_0-mlogloss:0.962835\n",
            "[51]\tvalidation_0-mlogloss:0.962967\n",
            "[52]\tvalidation_0-mlogloss:0.968378\n",
            "[53]\tvalidation_0-mlogloss:0.972458\n",
            "[54]\tvalidation_0-mlogloss:0.977171\n",
            "[55]\tvalidation_0-mlogloss:0.977215\n",
            "[56]\tvalidation_0-mlogloss:0.980546\n",
            "[57]\tvalidation_0-mlogloss:0.978686\n",
            "[58]\tvalidation_0-mlogloss:0.976557\n",
            "[59]\tvalidation_0-mlogloss:0.980073\n",
            "[60]\tvalidation_0-mlogloss:0.976401\n",
            "[61]\tvalidation_0-mlogloss:0.976926\n",
            "[62]\tvalidation_0-mlogloss:0.97766\n",
            "[63]\tvalidation_0-mlogloss:0.985175\n",
            "[64]\tvalidation_0-mlogloss:0.989387\n",
            "[65]\tvalidation_0-mlogloss:0.987432\n",
            "[66]\tvalidation_0-mlogloss:0.993763\n",
            "[67]\tvalidation_0-mlogloss:0.995341\n",
            "[68]\tvalidation_0-mlogloss:0.998175\n",
            "[69]\tvalidation_0-mlogloss:0.994441\n",
            "[70]\tvalidation_0-mlogloss:1.00185\n",
            "[71]\tvalidation_0-mlogloss:1.00021\n",
            "[72]\tvalidation_0-mlogloss:1.00225\n",
            "[73]\tvalidation_0-mlogloss:1.00303\n",
            "[74]\tvalidation_0-mlogloss:1.00775\n",
            "[75]\tvalidation_0-mlogloss:1.00905\n",
            "[76]\tvalidation_0-mlogloss:1.01022\n",
            "[77]\tvalidation_0-mlogloss:1.00849\n",
            "[78]\tvalidation_0-mlogloss:1.00927\n",
            "[79]\tvalidation_0-mlogloss:1.01142\n",
            "[80]\tvalidation_0-mlogloss:1.00988\n",
            "[81]\tvalidation_0-mlogloss:1.01127\n",
            "[82]\tvalidation_0-mlogloss:1.0127\n",
            "[83]\tvalidation_0-mlogloss:1.01314\n",
            "[84]\tvalidation_0-mlogloss:1.01395\n",
            "[85]\tvalidation_0-mlogloss:1.01459\n",
            "[86]\tvalidation_0-mlogloss:1.01366\n",
            "[87]\tvalidation_0-mlogloss:1.02059\n",
            "[88]\tvalidation_0-mlogloss:1.02038\n",
            "[89]\tvalidation_0-mlogloss:1.02407\n",
            "[90]\tvalidation_0-mlogloss:1.02263\n",
            "[91]\tvalidation_0-mlogloss:1.02386\n",
            "[92]\tvalidation_0-mlogloss:1.02389\n",
            "[93]\tvalidation_0-mlogloss:1.02764\n",
            "[94]\tvalidation_0-mlogloss:1.03189\n",
            "[95]\tvalidation_0-mlogloss:1.02937\n",
            "[96]\tvalidation_0-mlogloss:1.032\n",
            "[97]\tvalidation_0-mlogloss:1.0304\n",
            "[98]\tvalidation_0-mlogloss:1.03258\n",
            "[99]\tvalidation_0-mlogloss:1.03035\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.5, eval_metric='mlogloss', max_depth=5,\n",
              "              objective='multi:softprob', subsample=0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_test_preds = model_xgb_.predict_proba(X_test_ts).argmax(axis=1) # make predictions and find the index of the max predictions by row"
      ],
      "metadata": {
        "id": "8_ZSzURg_1IV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_acc_test = accuracy_score(y_test_ts, xgboost_test_preds) ; xgboost_acc_test # calculate Accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMiN1TP2AJaN",
        "outputId": "ecac56fc-c57e-4d22-9e10-ac60e808b1e7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5526315789473685"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_xgb, score_xgb = check_score(main, xgboost_test_preds) # calculate bookmakers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zevz8s5b_17Z",
        "outputId": "9be3c257-ebdb-4b8e-c60b-1ae0f8fb55b9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_xgb # And still we are below our initial investment."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bsCZ8-VA9Re",
        "outputId": "1dc42c5f-d013-49c7-8367-b6959ab3ce0a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75.53"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_odds_per_bet_xgb = compare_xgb.describe().loc[\"mean\"][\"score_odds\"] ; avg_odds_per_bet_xgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8vGByqW2cVA",
        "outputId": "cf84cd9f-d3c9-44af-fbca-3bc826879514"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7983333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost baseline performance\n",
        "It was slightly better then RandomForrest, but we are still underperforming. From the other hand, we are at the level of the bookmakers accuracy, so not bad for the second shot."
      ],
      "metadata": {
        "id": "8F43viU2WrVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TabNet Baseline"
      ],
      "metadata": {
        "id": "LySU1djKE67r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet==3.1.1 # You have to install tabnet, colab doesn't come with this one included"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEnU-ZheE81G",
        "outputId": "3e50565c-78d7-41c1-e2c1-0f46b80ae143"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_tabnet==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet==3.1.1) (4.64.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet==3.1.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet==3.1.1) (1.0.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet==3.1.1) (1.7.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet==3.1.1) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch_tabnet==3.1.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch_tabnet==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch_tabnet==3.1.1) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier #this is the class will be using\n",
        "import torch #this one is for the optimizer"
      ],
      "metadata": {
        "id": "AJ6W28bNFc2j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tabnet = TabNetClassifier(n_d=64, n_a=64, n_steps=10,\n",
        "    gamma=0, n_independent=2, n_shared=2,\n",
        "    lambda_sparse=1e-5, momentum=1, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.5,\n",
        "                     \"step_size\": 50},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ") #hyperparams of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJmOcIWBFjDW",
        "outputId": "ef9d872c-6a55-4ff6-b4c6-89ec44b773be"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 500 "
      ],
      "metadata": {
        "id": "OhzKvjOPF0uD"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tabnet.fit(X_train=X_train_ts, \n",
        "                 y_train=y_train_ts, \n",
        "                 eval_set=[(X_train_ts, y_train_ts), (X_test_ts, y_test_ts)],\n",
        "                 eval_name=['train','valid'],\n",
        "                 max_epochs=max_epochs, patience=100,) #train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjVQgD-eF4K4",
        "outputId": "d487a2d5-7767-4722-a089-4ef89220cfce"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 4.8647  | train_accuracy: 0.41447 | valid_accuracy: 0.46053 |  0:00:00s\n",
            "epoch 1  | loss: 1.8315  | train_accuracy: 0.48026 | valid_accuracy: 0.40789 |  0:00:00s\n",
            "epoch 2  | loss: 1.41701 | train_accuracy: 0.47697 | valid_accuracy: 0.44737 |  0:00:01s\n",
            "epoch 3  | loss: 1.06546 | train_accuracy: 0.5     | valid_accuracy: 0.5     |  0:00:01s\n",
            "epoch 4  | loss: 0.78156 | train_accuracy: 0.50658 | valid_accuracy: 0.5     |  0:00:01s\n",
            "epoch 5  | loss: 0.53857 | train_accuracy: 0.46711 | valid_accuracy: 0.51316 |  0:00:02s\n",
            "epoch 6  | loss: 0.4296  | train_accuracy: 0.44079 | valid_accuracy: 0.42105 |  0:00:02s\n",
            "epoch 7  | loss: 0.30506 | train_accuracy: 0.47368 | valid_accuracy: 0.43421 |  0:00:02s\n",
            "epoch 8  | loss: 0.67466 | train_accuracy: 0.40461 | valid_accuracy: 0.34211 |  0:00:03s\n",
            "epoch 9  | loss: 0.35327 | train_accuracy: 0.44408 | valid_accuracy: 0.48684 |  0:00:03s\n",
            "epoch 10 | loss: 0.34979 | train_accuracy: 0.44408 | valid_accuracy: 0.46053 |  0:00:03s\n",
            "epoch 11 | loss: 0.22378 | train_accuracy: 0.50329 | valid_accuracy: 0.51316 |  0:00:04s\n",
            "epoch 12 | loss: 0.30249 | train_accuracy: 0.47697 | valid_accuracy: 0.52632 |  0:00:04s\n",
            "epoch 13 | loss: 0.2824  | train_accuracy: 0.44079 | valid_accuracy: 0.46053 |  0:00:05s\n",
            "epoch 14 | loss: 0.1866  | train_accuracy: 0.49342 | valid_accuracy: 0.48684 |  0:00:05s\n",
            "epoch 15 | loss: 0.20383 | train_accuracy: 0.52632 | valid_accuracy: 0.53947 |  0:00:06s\n",
            "epoch 16 | loss: 0.16175 | train_accuracy: 0.47368 | valid_accuracy: 0.44737 |  0:00:06s\n",
            "epoch 17 | loss: 0.16238 | train_accuracy: 0.48355 | valid_accuracy: 0.47368 |  0:00:07s\n",
            "epoch 18 | loss: 0.11255 | train_accuracy: 0.47697 | valid_accuracy: 0.53947 |  0:00:07s\n",
            "epoch 19 | loss: 0.09625 | train_accuracy: 0.45066 | valid_accuracy: 0.47368 |  0:00:08s\n",
            "epoch 20 | loss: 0.18762 | train_accuracy: 0.45395 | valid_accuracy: 0.51316 |  0:00:09s\n",
            "epoch 21 | loss: 0.27809 | train_accuracy: 0.45724 | valid_accuracy: 0.47368 |  0:00:09s\n",
            "epoch 22 | loss: 0.05811 | train_accuracy: 0.4375  | valid_accuracy: 0.47368 |  0:00:10s\n",
            "epoch 23 | loss: 0.19854 | train_accuracy: 0.44408 | valid_accuracy: 0.5     |  0:00:11s\n",
            "epoch 24 | loss: 0.12317 | train_accuracy: 0.47697 | valid_accuracy: 0.51316 |  0:00:11s\n",
            "epoch 25 | loss: 0.08241 | train_accuracy: 0.42105 | valid_accuracy: 0.47368 |  0:00:12s\n",
            "epoch 26 | loss: 0.05726 | train_accuracy: 0.51645 | valid_accuracy: 0.5     |  0:00:12s\n",
            "epoch 27 | loss: 0.06405 | train_accuracy: 0.51316 | valid_accuracy: 0.5     |  0:00:13s\n",
            "epoch 28 | loss: 0.0857  | train_accuracy: 0.49342 | valid_accuracy: 0.56579 |  0:00:14s\n",
            "epoch 29 | loss: 0.11812 | train_accuracy: 0.46053 | valid_accuracy: 0.5     |  0:00:15s\n",
            "epoch 30 | loss: 0.02968 | train_accuracy: 0.46382 | valid_accuracy: 0.48684 |  0:00:15s\n",
            "epoch 31 | loss: 0.01984 | train_accuracy: 0.48026 | valid_accuracy: 0.52632 |  0:00:16s\n",
            "epoch 32 | loss: 0.01339 | train_accuracy: 0.45395 | valid_accuracy: 0.47368 |  0:00:16s\n",
            "epoch 33 | loss: 0.04103 | train_accuracy: 0.44079 | valid_accuracy: 0.48684 |  0:00:17s\n",
            "epoch 34 | loss: 0.04392 | train_accuracy: 0.46053 | valid_accuracy: 0.48684 |  0:00:18s\n",
            "epoch 35 | loss: 0.03345 | train_accuracy: 0.44079 | valid_accuracy: 0.47368 |  0:00:19s\n",
            "epoch 36 | loss: 0.01162 | train_accuracy: 0.47039 | valid_accuracy: 0.53947 |  0:00:19s\n",
            "epoch 37 | loss: 0.06016 | train_accuracy: 0.44408 | valid_accuracy: 0.5     |  0:00:20s\n",
            "epoch 38 | loss: 0.03445 | train_accuracy: 0.47368 | valid_accuracy: 0.53947 |  0:00:21s\n",
            "epoch 39 | loss: 0.01636 | train_accuracy: 0.46382 | valid_accuracy: 0.51316 |  0:00:21s\n",
            "epoch 40 | loss: 0.04535 | train_accuracy: 0.4375  | valid_accuracy: 0.5     |  0:00:22s\n",
            "epoch 41 | loss: 0.02587 | train_accuracy: 0.45724 | valid_accuracy: 0.5     |  0:00:22s\n",
            "epoch 42 | loss: 0.04671 | train_accuracy: 0.45724 | valid_accuracy: 0.5     |  0:00:22s\n",
            "epoch 43 | loss: 0.0396  | train_accuracy: 0.45724 | valid_accuracy: 0.48684 |  0:00:23s\n",
            "epoch 44 | loss: 0.07072 | train_accuracy: 0.48026 | valid_accuracy: 0.52632 |  0:00:23s\n",
            "epoch 45 | loss: 0.09952 | train_accuracy: 0.46382 | valid_accuracy: 0.52632 |  0:00:23s\n",
            "epoch 46 | loss: 0.06102 | train_accuracy: 0.45724 | valid_accuracy: 0.51316 |  0:00:24s\n",
            "epoch 47 | loss: 0.01678 | train_accuracy: 0.46053 | valid_accuracy: 0.5     |  0:00:24s\n",
            "epoch 48 | loss: 0.10999 | train_accuracy: 0.48026 | valid_accuracy: 0.46053 |  0:00:24s\n",
            "epoch 49 | loss: 0.01448 | train_accuracy: 0.44737 | valid_accuracy: 0.52632 |  0:00:24s\n",
            "epoch 50 | loss: 0.019   | train_accuracy: 0.47368 | valid_accuracy: 0.42105 |  0:00:25s\n",
            "epoch 51 | loss: 0.0556  | train_accuracy: 0.47039 | valid_accuracy: 0.51316 |  0:00:25s\n",
            "epoch 52 | loss: 0.01511 | train_accuracy: 0.53947 | valid_accuracy: 0.5     |  0:00:25s\n",
            "epoch 53 | loss: 0.01291 | train_accuracy: 0.47697 | valid_accuracy: 0.42105 |  0:00:26s\n",
            "epoch 54 | loss: 0.01809 | train_accuracy: 0.49013 | valid_accuracy: 0.55263 |  0:00:26s\n",
            "epoch 55 | loss: 0.00813 | train_accuracy: 0.46382 | valid_accuracy: 0.51316 |  0:00:26s\n",
            "epoch 56 | loss: 0.01045 | train_accuracy: 0.51645 | valid_accuracy: 0.51316 |  0:00:27s\n",
            "epoch 57 | loss: 0.00942 | train_accuracy: 0.49342 | valid_accuracy: 0.42105 |  0:00:27s\n",
            "epoch 58 | loss: 0.01412 | train_accuracy: 0.49342 | valid_accuracy: 0.47368 |  0:00:27s\n",
            "epoch 59 | loss: 0.01366 | train_accuracy: 0.47039 | valid_accuracy: 0.5     |  0:00:27s\n",
            "epoch 60 | loss: 0.00663 | train_accuracy: 0.46711 | valid_accuracy: 0.51316 |  0:00:28s\n",
            "epoch 61 | loss: 0.00533 | train_accuracy: 0.52303 | valid_accuracy: 0.51316 |  0:00:28s\n",
            "epoch 62 | loss: 0.00561 | train_accuracy: 0.51645 | valid_accuracy: 0.52632 |  0:00:28s\n",
            "epoch 63 | loss: 0.00848 | train_accuracy: 0.50658 | valid_accuracy: 0.46053 |  0:00:29s\n",
            "epoch 64 | loss: 0.00561 | train_accuracy: 0.49013 | valid_accuracy: 0.53947 |  0:00:29s\n",
            "epoch 65 | loss: 0.00524 | train_accuracy: 0.51645 | valid_accuracy: 0.48684 |  0:00:29s\n",
            "epoch 66 | loss: 0.0065  | train_accuracy: 0.48355 | valid_accuracy: 0.53947 |  0:00:30s\n",
            "epoch 67 | loss: 0.00877 | train_accuracy: 0.50658 | valid_accuracy: 0.5     |  0:00:30s\n",
            "epoch 68 | loss: 0.00507 | train_accuracy: 0.48026 | valid_accuracy: 0.53947 |  0:00:30s\n",
            "epoch 69 | loss: 0.00551 | train_accuracy: 0.50329 | valid_accuracy: 0.5     |  0:00:31s\n",
            "epoch 70 | loss: 0.00402 | train_accuracy: 0.51316 | valid_accuracy: 0.51316 |  0:00:31s\n",
            "epoch 71 | loss: 0.00435 | train_accuracy: 0.51645 | valid_accuracy: 0.51316 |  0:00:31s\n",
            "epoch 72 | loss: 0.00401 | train_accuracy: 0.51316 | valid_accuracy: 0.51316 |  0:00:31s\n",
            "epoch 73 | loss: 0.00353 | train_accuracy: 0.50329 | valid_accuracy: 0.52632 |  0:00:32s\n",
            "epoch 74 | loss: 0.00722 | train_accuracy: 0.46711 | valid_accuracy: 0.52632 |  0:00:32s\n",
            "epoch 75 | loss: 0.00318 | train_accuracy: 0.52961 | valid_accuracy: 0.55263 |  0:00:32s\n",
            "epoch 76 | loss: 0.00407 | train_accuracy: 0.52961 | valid_accuracy: 0.52632 |  0:00:33s\n",
            "epoch 77 | loss: 0.00301 | train_accuracy: 0.50329 | valid_accuracy: 0.5     |  0:00:33s\n",
            "epoch 78 | loss: 0.00293 | train_accuracy: 0.52303 | valid_accuracy: 0.53947 |  0:00:33s\n",
            "epoch 79 | loss: 0.00261 | train_accuracy: 0.51974 | valid_accuracy: 0.53947 |  0:00:34s\n",
            "epoch 80 | loss: 0.00275 | train_accuracy: 0.50987 | valid_accuracy: 0.51316 |  0:00:34s\n",
            "epoch 81 | loss: 0.0033  | train_accuracy: 0.52632 | valid_accuracy: 0.51316 |  0:00:34s\n",
            "epoch 82 | loss: 0.00353 | train_accuracy: 0.51645 | valid_accuracy: 0.46053 |  0:00:34s\n",
            "epoch 83 | loss: 0.00241 | train_accuracy: 0.52303 | valid_accuracy: 0.5     |  0:00:35s\n",
            "epoch 84 | loss: 0.00216 | train_accuracy: 0.52961 | valid_accuracy: 0.52632 |  0:00:35s\n",
            "epoch 85 | loss: 0.00281 | train_accuracy: 0.52632 | valid_accuracy: 0.51316 |  0:00:35s\n",
            "epoch 86 | loss: 0.00238 | train_accuracy: 0.50329 | valid_accuracy: 0.51316 |  0:00:36s\n",
            "epoch 87 | loss: 0.0025  | train_accuracy: 0.51316 | valid_accuracy: 0.56579 |  0:00:36s\n",
            "epoch 88 | loss: 0.00242 | train_accuracy: 0.52961 | valid_accuracy: 0.52632 |  0:00:36s\n",
            "epoch 89 | loss: 0.00307 | train_accuracy: 0.52632 | valid_accuracy: 0.5     |  0:00:37s\n",
            "epoch 90 | loss: 0.00229 | train_accuracy: 0.48684 | valid_accuracy: 0.48684 |  0:00:37s\n",
            "epoch 91 | loss: 0.0018  | train_accuracy: 0.53289 | valid_accuracy: 0.47368 |  0:00:37s\n",
            "epoch 92 | loss: 0.00234 | train_accuracy: 0.52632 | valid_accuracy: 0.47368 |  0:00:37s\n",
            "epoch 93 | loss: 0.00177 | train_accuracy: 0.54605 | valid_accuracy: 0.51316 |  0:00:38s\n",
            "epoch 94 | loss: 0.00218 | train_accuracy: 0.50658 | valid_accuracy: 0.47368 |  0:00:38s\n",
            "epoch 95 | loss: 0.00658 | train_accuracy: 0.49013 | valid_accuracy: 0.47368 |  0:00:38s\n",
            "epoch 96 | loss: 0.0022  | train_accuracy: 0.51316 | valid_accuracy: 0.48684 |  0:00:39s\n",
            "epoch 97 | loss: 0.0019  | train_accuracy: 0.52632 | valid_accuracy: 0.48684 |  0:00:39s\n",
            "epoch 98 | loss: 0.00179 | train_accuracy: 0.52303 | valid_accuracy: 0.55263 |  0:00:39s\n",
            "epoch 99 | loss: 0.0015  | train_accuracy: 0.54605 | valid_accuracy: 0.51316 |  0:00:40s\n",
            "epoch 100| loss: 0.00154 | train_accuracy: 0.52632 | valid_accuracy: 0.52632 |  0:00:40s\n",
            "epoch 101| loss: 0.00141 | train_accuracy: 0.53947 | valid_accuracy: 0.51316 |  0:00:40s\n",
            "epoch 102| loss: 0.0016  | train_accuracy: 0.51974 | valid_accuracy: 0.44737 |  0:00:40s\n",
            "epoch 103| loss: 0.00163 | train_accuracy: 0.52632 | valid_accuracy: 0.5     |  0:00:41s\n",
            "epoch 104| loss: 0.00142 | train_accuracy: 0.50658 | valid_accuracy: 0.55263 |  0:00:41s\n",
            "epoch 105| loss: 0.00178 | train_accuracy: 0.51645 | valid_accuracy: 0.52632 |  0:00:41s\n",
            "epoch 106| loss: 0.00169 | train_accuracy: 0.50987 | valid_accuracy: 0.46053 |  0:00:42s\n",
            "epoch 107| loss: 0.00157 | train_accuracy: 0.53289 | valid_accuracy: 0.47368 |  0:00:42s\n",
            "epoch 108| loss: 0.00165 | train_accuracy: 0.51645 | valid_accuracy: 0.46053 |  0:00:42s\n",
            "epoch 109| loss: 0.00149 | train_accuracy: 0.53947 | valid_accuracy: 0.46053 |  0:00:43s\n",
            "epoch 110| loss: 0.00174 | train_accuracy: 0.55263 | valid_accuracy: 0.52632 |  0:00:43s\n",
            "epoch 111| loss: 0.00164 | train_accuracy: 0.52303 | valid_accuracy: 0.53947 |  0:00:43s\n",
            "epoch 112| loss: 0.00149 | train_accuracy: 0.53289 | valid_accuracy: 0.44737 |  0:00:43s\n",
            "epoch 113| loss: 0.0016  | train_accuracy: 0.52303 | valid_accuracy: 0.51316 |  0:00:44s\n",
            "epoch 114| loss: 0.00134 | train_accuracy: 0.55921 | valid_accuracy: 0.46053 |  0:00:44s\n",
            "epoch 115| loss: 0.00144 | train_accuracy: 0.55592 | valid_accuracy: 0.53947 |  0:00:44s\n",
            "epoch 116| loss: 0.0019  | train_accuracy: 0.51645 | valid_accuracy: 0.44737 |  0:00:45s\n",
            "epoch 117| loss: 0.00154 | train_accuracy: 0.50987 | valid_accuracy: 0.46053 |  0:00:45s\n",
            "epoch 118| loss: 0.00172 | train_accuracy: 0.54605 | valid_accuracy: 0.52632 |  0:00:45s\n",
            "epoch 119| loss: 0.00124 | train_accuracy: 0.55921 | valid_accuracy: 0.52632 |  0:00:46s\n",
            "epoch 120| loss: 0.00177 | train_accuracy: 0.52303 | valid_accuracy: 0.43421 |  0:00:46s\n",
            "epoch 121| loss: 0.00148 | train_accuracy: 0.53947 | valid_accuracy: 0.53947 |  0:00:46s\n",
            "epoch 122| loss: 0.00144 | train_accuracy: 0.53618 | valid_accuracy: 0.48684 |  0:00:46s\n",
            "epoch 123| loss: 0.0015  | train_accuracy: 0.54934 | valid_accuracy: 0.57895 |  0:00:47s\n",
            "epoch 124| loss: 0.00139 | train_accuracy: 0.55592 | valid_accuracy: 0.44737 |  0:00:47s\n",
            "epoch 125| loss: 0.00207 | train_accuracy: 0.51974 | valid_accuracy: 0.46053 |  0:00:47s\n",
            "epoch 126| loss: 0.00137 | train_accuracy: 0.52303 | valid_accuracy: 0.5     |  0:00:48s\n",
            "epoch 127| loss: 0.00116 | train_accuracy: 0.55921 | valid_accuracy: 0.47368 |  0:00:48s\n",
            "epoch 128| loss: 0.0013  | train_accuracy: 0.59211 | valid_accuracy: 0.59211 |  0:00:48s\n",
            "epoch 129| loss: 0.00149 | train_accuracy: 0.52632 | valid_accuracy: 0.48684 |  0:00:49s\n",
            "epoch 130| loss: 0.00156 | train_accuracy: 0.52303 | valid_accuracy: 0.51316 |  0:00:49s\n",
            "epoch 131| loss: 0.0014  | train_accuracy: 0.55263 | valid_accuracy: 0.5     |  0:00:49s\n",
            "epoch 132| loss: 0.00108 | train_accuracy: 0.57895 | valid_accuracy: 0.51316 |  0:00:49s\n",
            "epoch 133| loss: 0.0012  | train_accuracy: 0.58553 | valid_accuracy: 0.53947 |  0:00:50s\n",
            "epoch 134| loss: 0.00118 | train_accuracy: 0.58553 | valid_accuracy: 0.5     |  0:00:50s\n",
            "epoch 135| loss: 0.001   | train_accuracy: 0.56579 | valid_accuracy: 0.53947 |  0:00:50s\n",
            "epoch 136| loss: 0.00148 | train_accuracy: 0.55921 | valid_accuracy: 0.48684 |  0:00:51s\n",
            "epoch 137| loss: 0.0015  | train_accuracy: 0.55592 | valid_accuracy: 0.48684 |  0:00:51s\n",
            "epoch 138| loss: 0.00117 | train_accuracy: 0.55921 | valid_accuracy: 0.5     |  0:00:51s\n",
            "epoch 139| loss: 0.00105 | train_accuracy: 0.57237 | valid_accuracy: 0.51316 |  0:00:52s\n",
            "epoch 140| loss: 0.00109 | train_accuracy: 0.61513 | valid_accuracy: 0.57895 |  0:00:52s\n",
            "epoch 141| loss: 0.00087 | train_accuracy: 0.58882 | valid_accuracy: 0.55263 |  0:00:52s\n",
            "epoch 142| loss: 0.00145 | train_accuracy: 0.58553 | valid_accuracy: 0.5     |  0:00:52s\n",
            "epoch 143| loss: 0.00133 | train_accuracy: 0.58553 | valid_accuracy: 0.57895 |  0:00:53s\n",
            "epoch 144| loss: 0.00134 | train_accuracy: 0.58882 | valid_accuracy: 0.52632 |  0:00:53s\n",
            "epoch 145| loss: 0.0015  | train_accuracy: 0.60526 | valid_accuracy: 0.5     |  0:00:53s\n",
            "epoch 146| loss: 0.00153 | train_accuracy: 0.55921 | valid_accuracy: 0.52632 |  0:00:54s\n",
            "epoch 147| loss: 0.00114 | train_accuracy: 0.58553 | valid_accuracy: 0.53947 |  0:00:54s\n",
            "epoch 148| loss: 0.00119 | train_accuracy: 0.625   | valid_accuracy: 0.55263 |  0:00:54s\n",
            "epoch 149| loss: 0.0011  | train_accuracy: 0.58553 | valid_accuracy: 0.51316 |  0:00:55s\n",
            "epoch 150| loss: 0.0012  | train_accuracy: 0.55921 | valid_accuracy: 0.5     |  0:00:55s\n",
            "epoch 151| loss: 0.00119 | train_accuracy: 0.62829 | valid_accuracy: 0.52632 |  0:00:55s\n",
            "epoch 152| loss: 0.0014  | train_accuracy: 0.60855 | valid_accuracy: 0.48684 |  0:00:55s\n",
            "epoch 153| loss: 0.00124 | train_accuracy: 0.625   | valid_accuracy: 0.5     |  0:00:56s\n",
            "epoch 154| loss: 0.00086 | train_accuracy: 0.61842 | valid_accuracy: 0.51316 |  0:00:56s\n",
            "epoch 155| loss: 0.00128 | train_accuracy: 0.63816 | valid_accuracy: 0.5     |  0:00:56s\n",
            "epoch 156| loss: 0.00094 | train_accuracy: 0.625   | valid_accuracy: 0.48684 |  0:00:57s\n",
            "epoch 157| loss: 0.00119 | train_accuracy: 0.64145 | valid_accuracy: 0.52632 |  0:00:57s\n",
            "epoch 158| loss: 0.00096 | train_accuracy: 0.65132 | valid_accuracy: 0.51316 |  0:00:57s\n",
            "epoch 159| loss: 0.00099 | train_accuracy: 0.60197 | valid_accuracy: 0.5     |  0:00:58s\n",
            "epoch 160| loss: 0.00118 | train_accuracy: 0.65461 | valid_accuracy: 0.53947 |  0:00:58s\n",
            "epoch 161| loss: 0.00087 | train_accuracy: 0.65789 | valid_accuracy: 0.48684 |  0:00:58s\n",
            "epoch 162| loss: 0.00099 | train_accuracy: 0.67105 | valid_accuracy: 0.56579 |  0:00:58s\n",
            "epoch 163| loss: 0.00095 | train_accuracy: 0.65132 | valid_accuracy: 0.5     |  0:00:59s\n",
            "epoch 164| loss: 0.00512 | train_accuracy: 0.64145 | valid_accuracy: 0.51316 |  0:00:59s\n",
            "epoch 165| loss: 0.00113 | train_accuracy: 0.66776 | valid_accuracy: 0.52632 |  0:00:59s\n",
            "epoch 166| loss: 0.00108 | train_accuracy: 0.65461 | valid_accuracy: 0.51316 |  0:01:00s\n",
            "epoch 167| loss: 0.0012  | train_accuracy: 0.72039 | valid_accuracy: 0.53947 |  0:01:00s\n",
            "epoch 168| loss: 0.00115 | train_accuracy: 0.69408 | valid_accuracy: 0.53947 |  0:01:00s\n",
            "epoch 169| loss: 0.00097 | train_accuracy: 0.6875  | valid_accuracy: 0.56579 |  0:01:01s\n",
            "epoch 170| loss: 0.0012  | train_accuracy: 0.68421 | valid_accuracy: 0.52632 |  0:01:01s\n",
            "epoch 171| loss: 0.00132 | train_accuracy: 0.72368 | valid_accuracy: 0.52632 |  0:01:01s\n",
            "epoch 172| loss: 0.00141 | train_accuracy: 0.70395 | valid_accuracy: 0.51316 |  0:01:01s\n",
            "epoch 173| loss: 0.00773 | train_accuracy: 0.72039 | valid_accuracy: 0.55263 |  0:01:02s\n",
            "epoch 174| loss: 0.00265 | train_accuracy: 0.74342 | valid_accuracy: 0.5     |  0:01:02s\n",
            "epoch 175| loss: 0.00098 | train_accuracy: 0.65789 | valid_accuracy: 0.55263 |  0:01:02s\n",
            "epoch 176| loss: 0.00076 | train_accuracy: 0.72368 | valid_accuracy: 0.57895 |  0:01:03s\n",
            "epoch 177| loss: 0.00136 | train_accuracy: 0.74013 | valid_accuracy: 0.5     |  0:01:03s\n",
            "epoch 178| loss: 0.00155 | train_accuracy: 0.70395 | valid_accuracy: 0.5     |  0:01:03s\n",
            "epoch 179| loss: 0.00102 | train_accuracy: 0.76316 | valid_accuracy: 0.55263 |  0:01:03s\n",
            "epoch 180| loss: 0.00105 | train_accuracy: 0.67434 | valid_accuracy: 0.47368 |  0:01:04s\n",
            "epoch 181| loss: 0.00105 | train_accuracy: 0.73026 | valid_accuracy: 0.47368 |  0:01:04s\n",
            "epoch 182| loss: 0.00192 | train_accuracy: 0.75987 | valid_accuracy: 0.56579 |  0:01:04s\n",
            "epoch 183| loss: 0.0009  | train_accuracy: 0.75329 | valid_accuracy: 0.55263 |  0:01:05s\n",
            "epoch 184| loss: 0.00102 | train_accuracy: 0.79934 | valid_accuracy: 0.52632 |  0:01:05s\n",
            "epoch 185| loss: 0.00146 | train_accuracy: 0.73355 | valid_accuracy: 0.55263 |  0:01:05s\n",
            "epoch 186| loss: 0.00104 | train_accuracy: 0.75987 | valid_accuracy: 0.53947 |  0:01:06s\n",
            "epoch 187| loss: 0.00095 | train_accuracy: 0.75987 | valid_accuracy: 0.52632 |  0:01:06s\n",
            "epoch 188| loss: 0.00132 | train_accuracy: 0.76645 | valid_accuracy: 0.53947 |  0:01:06s\n",
            "epoch 189| loss: 0.00149 | train_accuracy: 0.78289 | valid_accuracy: 0.53947 |  0:01:07s\n",
            "epoch 190| loss: 0.00096 | train_accuracy: 0.76974 | valid_accuracy: 0.55263 |  0:01:07s\n",
            "epoch 191| loss: 0.00297 | train_accuracy: 0.80592 | valid_accuracy: 0.53947 |  0:01:07s\n",
            "epoch 192| loss: 0.00158 | train_accuracy: 0.75658 | valid_accuracy: 0.44737 |  0:01:07s\n",
            "epoch 193| loss: 0.00109 | train_accuracy: 0.79605 | valid_accuracy: 0.52632 |  0:01:08s\n",
            "epoch 194| loss: 0.00116 | train_accuracy: 0.78947 | valid_accuracy: 0.5     |  0:01:08s\n",
            "epoch 195| loss: 0.00132 | train_accuracy: 0.79934 | valid_accuracy: 0.53947 |  0:01:08s\n",
            "epoch 196| loss: 0.00114 | train_accuracy: 0.78618 | valid_accuracy: 0.53947 |  0:01:09s\n",
            "epoch 197| loss: 0.00096 | train_accuracy: 0.82237 | valid_accuracy: 0.53947 |  0:01:09s\n",
            "epoch 198| loss: 0.00128 | train_accuracy: 0.82566 | valid_accuracy: 0.56579 |  0:01:09s\n",
            "epoch 199| loss: 0.00112 | train_accuracy: 0.81908 | valid_accuracy: 0.51316 |  0:01:09s\n",
            "epoch 200| loss: 0.0013  | train_accuracy: 0.77961 | valid_accuracy: 0.52632 |  0:01:10s\n",
            "epoch 201| loss: 0.00102 | train_accuracy: 0.79934 | valid_accuracy: 0.52632 |  0:01:10s\n",
            "epoch 202| loss: 0.00111 | train_accuracy: 0.82237 | valid_accuracy: 0.55263 |  0:01:10s\n",
            "epoch 203| loss: 0.00361 | train_accuracy: 0.81908 | valid_accuracy: 0.5     |  0:01:11s\n",
            "epoch 204| loss: 0.00098 | train_accuracy: 0.84539 | valid_accuracy: 0.51316 |  0:01:11s\n",
            "epoch 205| loss: 0.00135 | train_accuracy: 0.84868 | valid_accuracy: 0.52632 |  0:01:11s\n",
            "epoch 206| loss: 0.00101 | train_accuracy: 0.86842 | valid_accuracy: 0.57895 |  0:01:12s\n",
            "epoch 207| loss: 0.00094 | train_accuracy: 0.85197 | valid_accuracy: 0.5     |  0:01:12s\n",
            "epoch 208| loss: 0.00088 | train_accuracy: 0.85855 | valid_accuracy: 0.55263 |  0:01:12s\n",
            "epoch 209| loss: 0.00102 | train_accuracy: 0.84539 | valid_accuracy: 0.48684 |  0:01:12s\n",
            "epoch 210| loss: 0.00123 | train_accuracy: 0.85197 | valid_accuracy: 0.57895 |  0:01:13s\n",
            "epoch 211| loss: 0.00108 | train_accuracy: 0.83882 | valid_accuracy: 0.53947 |  0:01:13s\n",
            "epoch 212| loss: 0.00105 | train_accuracy: 0.84868 | valid_accuracy: 0.51316 |  0:01:13s\n",
            "epoch 213| loss: 0.00135 | train_accuracy: 0.79934 | valid_accuracy: 0.5     |  0:01:14s\n",
            "epoch 214| loss: 0.001   | train_accuracy: 0.83882 | valid_accuracy: 0.55263 |  0:01:14s\n",
            "epoch 215| loss: 0.00089 | train_accuracy: 0.89145 | valid_accuracy: 0.52632 |  0:01:14s\n",
            "epoch 216| loss: 0.00093 | train_accuracy: 0.84211 | valid_accuracy: 0.53947 |  0:01:15s\n",
            "epoch 217| loss: 0.00086 | train_accuracy: 0.83224 | valid_accuracy: 0.51316 |  0:01:15s\n",
            "epoch 218| loss: 0.00085 | train_accuracy: 0.83224 | valid_accuracy: 0.55263 |  0:01:15s\n",
            "epoch 219| loss: 0.00112 | train_accuracy: 0.86513 | valid_accuracy: 0.52632 |  0:01:15s\n",
            "epoch 220| loss: 0.00072 | train_accuracy: 0.85855 | valid_accuracy: 0.59211 |  0:01:16s\n",
            "epoch 221| loss: 0.00099 | train_accuracy: 0.89145 | valid_accuracy: 0.53947 |  0:01:16s\n",
            "epoch 222| loss: 0.00092 | train_accuracy: 0.90789 | valid_accuracy: 0.59211 |  0:01:16s\n",
            "epoch 223| loss: 0.001   | train_accuracy: 0.86184 | valid_accuracy: 0.59211 |  0:01:17s\n",
            "epoch 224| loss: 0.00107 | train_accuracy: 0.87829 | valid_accuracy: 0.48684 |  0:01:17s\n",
            "epoch 225| loss: 0.00134 | train_accuracy: 0.91118 | valid_accuracy: 0.46053 |  0:01:17s\n",
            "epoch 226| loss: 0.0012  | train_accuracy: 0.87829 | valid_accuracy: 0.53947 |  0:01:18s\n",
            "epoch 227| loss: 0.00109 | train_accuracy: 0.875   | valid_accuracy: 0.53947 |  0:01:18s\n",
            "epoch 228| loss: 0.00104 | train_accuracy: 0.87829 | valid_accuracy: 0.56579 |  0:01:18s\n",
            "\n",
            "Early stopping occurred at epoch 228 with best_epoch = 128 and best_valid_accuracy = 0.59211\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_predictions = model_tabnet.predict_proba(X_test_ts).argmax(axis=1) # predictions"
      ],
      "metadata": {
        "id": "VwYh_0W1G0f5"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_accuracy = accuracy_score(y_test_ts, tabnet_predictions)  ; tabnet_accuracy # accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xRPjCQ6HGpH",
        "outputId": "2f9f0bf3-34c1-4249-a15d-63b381725b50"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5921052631578947"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_tabnet, score_tabnet = check_score(main, tabnet_predictions) # checking the score against the odds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5FKPpnVHZ5R",
        "outputId": "5001131a-a5be-42bf-b065-9bf72bf3942b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHJ0B_DHh63",
        "outputId": "94f89f31-b814-48d1-b83e-0be90990f1d5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.46"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_odds_per_bet_tabnet = compare_tabnet.describe().loc[\"mean\"][\"score_odds\"] ; avg_odds_per_bet_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDBrVU82T9d",
        "outputId": "82abe8da-af54-40a0-dfb9-fd4b59c9d869"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0546666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepInsight like model\n",
        "Below code is PyTorch specific and I will not be explaining erything very precisle here. If you don't know this framework specificly well and want to change it, consider this:\n",
        "\n",
        "https://www.mrdbourke.com/pytorch-in-a-day/"
      ],
      "metadata": {
        "id": "9RO36Blzbfme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics # for accuracy\n",
        "!pip install tab2img # for DeepInsight implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7vnCT5rbezJ",
        "outputId": "0879d7d5-e996-4247-e50c-8bd9f957ebb8"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tab2img in /usr/local/lib/python3.7/dist-packages (0.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn  #we previously import torch, this one is just for the module of neural nets.\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "D1VQUJVAkJ6w"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tab2img.converter import Tab2Img # import Class to convert the tabular data into images\n",
        "import requests # for downloading my custom pytorch loops and some other hlepful classess.\n",
        "\n",
        "\n",
        "if Path(\"helper_f.py\").is_file(): \n",
        "    print(\"Exists!\")\n",
        "else:\n",
        "    print(\"Dwnld\")\n",
        "    request = requests.get(\"https://raw.githubusercontent.com/SquareGraph/HelperFunctions/main/helper_f.py\")\n",
        "    with open(\"helper_f.py\", \"wb\") as f:\n",
        "        f.write(request.content)\n",
        "\n",
        "from helper_f import * #importing those helper functions I mentioned above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWL9hOBBeMiA",
        "outputId": "fcbdb42a-909f-4655-fab9-cb2ebea0551d"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #device agnostic code."
      ],
      "metadata": {
        "id": "8ABGGk3keb5R"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will define a converter. It will do two things. Firstly we are about to call a class to apply transmutation on the table data.\n",
        "# Secondly we will broadcast it into the NCHW format.\n",
        "\n",
        "def tab2_img_xy(train,target,channels:int = 3):\n",
        "    model_converter = Tab2Img()\n",
        "    X = model_converter.fit_transform(train,target)\n",
        "    dim = X[0][1].shape \n",
        "\n",
        "    list_of_3d_img = []\n",
        "    for image in X:\n",
        "        list_of_3d_img.append(np.broadcast_to(image, (channels,dim[0],dim[0]))) \n",
        "\n",
        "    return torch.tensor(np.array(list_of_3d_img, dtype=np.float32))\n"
      ],
      "metadata": {
        "id": "wdABpOUvfguX"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensors_train = tab2_img_xy(X, y, 1) # calling the function to get tensors"
      ],
      "metadata": {
        "id": "1RfPEvkxgExP"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensors_train.shape # so we have all of our data in one tensor. Now it's time to plot it to check how it looks like."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6B38oITgFAG",
        "outputId": "235dde0e-e434-45fa-ac86-01e9a7144566"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([380, 1, 12, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_ranom_images(0,380,12,X_tensors_train, y, (18,18), (4,3) , 10) #hleper function that takes out random sample from tensor, transmute them to the HWC format (matplotlib do not understand PyTorch native image format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lrxO0M5GgFC5",
        "outputId": "331aea11-c3f5-4fe7-e510-c40b9772d847"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x1296 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # This time I'm using whole dataframe for y labels, because I have already prebuild PyTorch DataSet Class that will handle extracting y values.\n",
        "train_tensor, test_tensor = train_test_split_ts(X_tensors_train, main, train_size=0.8)"
      ],
      "metadata": {
        "id": "EZdT9jVcgFFP"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor, y_train_tensor = train_tensor\n",
        "X_test_tensor, y_test_tensor = test_tensor # unpacking tuples"
      ],
      "metadata": {
        "id": "frAKE2sggFIt"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes(series: pd.core.series.Series):\n",
        "\n",
        "    classes = series.unique()\n",
        "    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "\n",
        "    return classes, class_to_idx\n",
        "\n",
        "class MatchesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, \n",
        "                 dataframe: pd.core.frame.DataFrame, #dataframe of results, we will gety Y_labels from this\n",
        "                 games: torch.Tensor, #tensor of X's\n",
        "                 transform=None): #we will not be using any transorm at this stage, but I'll leave as a boiler plate for further usage.\n",
        "        super().__init__()\n",
        "\n",
        "        self.dataframe = dataframe #a dataframe as it it.\n",
        "        self.games = games # our X's. We don't have to do anything with them, cause if we index this tensor, we will have a single image of a game from it.\n",
        "        self.hda = self.dataframe[\"FTR\"].to_numpy() #we are transforming pandas datafram to numpy array of Home/Draw/Away labels.\n",
        "        self.classes, self.class_to_idx = get_classes(dataframe[\"FTR\"]) #we are unpacking a function that will return us a mapped y labels.\n",
        "        self.labels = torch.tensor(np.vectorize(self.class_to_idx.get)(self.hda)) #and here we are using np.vectorize to turn coresponding labels into values from 0 to 2 and then we turn them into a tensor.\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels) #overwriting __len__\n",
        "\n",
        "    def __getitem__(self, index: int): #overwriting __getitem__ and returning X&y's\n",
        "    \n",
        "        X = self.games[index]\n",
        "        y = self.labels[index]\n",
        "        \n",
        "        return X,y\n"
      ],
      "metadata": {
        "id": "OamY5WPujn1u"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we initialize a class to create a PyTorch Datasets\n",
        "train_dataset = MatchesDataset(y_train_tensor,X_train_tensor) \n",
        "test_dataset = MatchesDataset(y_test_tensor,X_test_tensor)"
      ],
      "metadata": {
        "id": "0pwonNtyjoAM"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#And this part of code is clustering data into minibatches and preparing an efficient datapipe for the CNN \n",
        "train_loader_tab2img = DataLoader(train_dataset, 16, shuffle=False) # we are not shuffling, to be consistent. \n",
        "test_loader_tab2img = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "D3uu39aSjoKC"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It's not exactly a DeepInsight, but it's a similar, despite hyperparams may vary. Remember, it's a baseline only!\n",
        "class DeepInsightStyleNN(nn.Module): \n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int,) -> None:\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = input_shape,\n",
        "                      out_channels = hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        \n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = hidden_units,\n",
        "                      out_channels = hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        \n",
        "        self.conv_block_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = hidden_units,\n",
        "                      out_channels = hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        \n",
        "        self.conv_block_3_5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = hidden_units,\n",
        "                      out_channels = hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        \n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=10,\n",
        "                      out_features=output_shape),\n",
        "            nn.Softmax()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier_layer(self.conv_block_3_5(self.conv_block_3(self.conv_block_2(self.conv_block_1(x)))))   #for efficiency on cuda computing we are doing this in one line."
      ],
      "metadata": {
        "id": "5kTWh51hjoR-"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_in_model = DeepInsightStyleNN(input_shape=1,\n",
        "                    hidden_units=10,\n",
        "                    output_shape=np.unique(y).shape[0]).to(device) # initialize the model"
      ],
      "metadata": {
        "id": "MuEN8Uk5oekx"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_in_model.eval()\n",
        "with torch.inference_mode():\n",
        "    preds = deep_in_model(X_tensors_train) # check if the output have sense"
      ],
      "metadata": {
        "id": "MIXdgGdYofAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aca9106-0acf-4436-a942-fb59b23cb12f"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape # indeed, it have proper shape."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2wd5fjEofDf",
        "outputId": "8338b764-af9a-441d-df8b-adaccbf2609d"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([380, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we have to define metrics, loss function and optimizer\n",
        "\n",
        "optimizer_deep = torch.optim.Adam(deep_in_model.parameters(),lr=0.001) #Adam as an optimizer\n",
        "loss_fn_deep = nn.CrossEntropyLoss() #Cause we are dealing with multicategory classification, we will use Cross Entropy\n",
        "acc_deep = torchmetrics.Accuracy(3).to(device) #and we also initialize class from torchmetrics and send it to device(cuda). "
      ],
      "metadata": {
        "id": "1MgriBTIofGx"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And it's a training time\n",
        "for epoch in tqdm(range(60)):\n",
        "\n",
        "    print(f\"Epoch: {epoch}\\n======\")\n",
        "\n",
        "    train_step(deep_in_model,train_loader_tab2img,loss_fn_deep, optimizer_deep, acc_deep, device)\n",
        "    test_step(deep_in_model,test_loader_tab2img,loss_fn_deep, acc_deep, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-vUqxMVofJA",
        "outputId": "cf46bcd4-8417-4b60-9a2d-8d12e767405f"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "======\n",
            "\n",
            "Current training loss: 1.092272400856018\n",
            "Current training acc: 0.3486842215061188%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 399.92it/s]\n",
            "  2%|▏         | 1/60 [00:00<00:25,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.096718430519104\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 1\n",
            "======\n",
            "\n",
            "Current training loss: 1.0616636276245117\n",
            "Current training acc: 0.47697368264198303%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 574.20it/s]\n",
            "  3%|▎         | 2/60 [00:00<00:19,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.1197967529296875\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 2\n",
            "======\n",
            "\n",
            "Current training loss: 1.04583740234375\n",
            "Current training acc: 0.5625%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 607.68it/s]\n",
            "  5%|▌         | 3/60 [00:00<00:17,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.1758222579956055\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 3\n",
            "======\n",
            "\n",
            "Current training loss: 1.034127950668335\n",
            "Current training acc: 0.5723684430122375%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 570.59it/s]\n",
            "  7%|▋         | 4/60 [00:01<00:16,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.180324912071228\n",
            "Current test acc: 0.28947368264198303%\n",
            "\n",
            "Epoch: 4\n",
            "======\n",
            "\n",
            "Current training loss: 1.0239176750183105\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 661.36it/s]\n",
            "  8%|▊         | 5/60 [00:01<00:15,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2086998224258423\n",
            "Current test acc: 0.2368421107530594%\n",
            "\n",
            "Epoch: 5\n",
            "======\n",
            "\n",
            "Current training loss: 1.0155783891677856\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 490.99it/s]\n",
            " 10%|█         | 6/60 [00:01<00:14,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2090680599212646\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 6\n",
            "======\n",
            "\n",
            "Current training loss: 1.0087099075317383\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 439.30it/s]\n",
            " 12%|█▏        | 7/60 [00:02<00:16,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2026219367980957\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 7\n",
            "======\n",
            "\n",
            "Current training loss: 1.002132534980774\n",
            "Current training acc: 0.5756579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 653.70it/s]\n",
            " 13%|█▎        | 8/60 [00:02<00:14,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2568411827087402\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 8\n",
            "======\n",
            "\n",
            "Current training loss: 0.9975134134292603\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 638.60it/s]\n",
            " 15%|█▌        | 9/60 [00:02<00:13,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2112016677856445\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 9\n",
            "======\n",
            "\n",
            "Current training loss: 0.9925519824028015\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 635.91it/s]\n",
            " 17%|█▋        | 10/60 [00:02<00:13,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2345926761627197\n",
            "Current test acc: 0.25%\n",
            "\n",
            "Epoch: 10\n",
            "======\n",
            "\n",
            "Current training loss: 0.9884960651397705\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 607.20it/s]\n",
            " 18%|█▊        | 11/60 [00:03<00:12,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.197988510131836\n",
            "Current test acc: 0.25%\n",
            "\n",
            "Epoch: 11\n",
            "======\n",
            "\n",
            "Current training loss: 0.9839898347854614\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 632.17it/s]\n",
            " 20%|██        | 12/60 [00:03<00:12,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2370554208755493\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 12\n",
            "======\n",
            "\n",
            "Current training loss: 0.9817593097686768\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 638.56it/s]\n",
            " 22%|██▏       | 13/60 [00:03<00:11,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.228173851966858\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 13\n",
            "======\n",
            "\n",
            "Current training loss: 0.9791114330291748\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 617.63it/s]\n",
            " 23%|██▎       | 14/60 [00:03<00:11,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.247178077697754\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 14\n",
            "======\n",
            "\n",
            "Current training loss: 0.9757310152053833\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 575.25it/s]\n",
            " 25%|██▌       | 15/60 [00:04<00:11,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2259665727615356\n",
            "Current test acc: 0.28947368264198303%\n",
            "\n",
            "Epoch: 15\n",
            "======\n",
            "\n",
            "Current training loss: 0.973044216632843\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 410.58it/s]\n",
            " 27%|██▋       | 16/60 [00:04<00:14,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2354564666748047\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 16\n",
            "======\n",
            "\n",
            "Current training loss: 0.9717225432395935\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 387.70it/s]\n",
            " 28%|██▊       | 17/60 [00:04<00:14,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.221290946006775\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 17\n",
            "======\n",
            "\n",
            "Current training loss: 0.9686367511749268\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 370.46it/s]\n",
            " 30%|███       | 18/60 [00:05<00:15,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2517893314361572\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 18\n",
            "======\n",
            "\n",
            "Current training loss: 0.9674179553985596\n",
            "Current training acc: 0.5822368264198303%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 349.24it/s]\n",
            " 32%|███▏      | 19/60 [00:05<00:16,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2360882759094238\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 19\n",
            "======\n",
            "\n",
            "Current training loss: 0.9645915031433105\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 365.15it/s]\n",
            " 33%|███▎      | 20/60 [00:06<00:17,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2522460222244263\n",
            "Current test acc: 0.25%\n",
            "\n",
            "Epoch: 20\n",
            "======\n",
            "\n",
            "Current training loss: 0.9679581522941589\n",
            "Current training acc: 0.5822368264198303%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 38%|███▊      | 29/76 [00:00<00:00, 285.42it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 290.23it/s]\n",
            " 35%|███▌      | 21/60 [00:06<00:17,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2621546983718872\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 21\n",
            "======\n",
            "\n",
            "Current training loss: 0.9641371369361877\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 378.73it/s]\n",
            " 37%|███▋      | 22/60 [00:07<00:16,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.287172794342041\n",
            "Current test acc: 0.19736842811107635%\n",
            "\n",
            "Epoch: 22\n",
            "======\n",
            "\n",
            "Current training loss: 0.9601505398750305\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 426.01it/s]\n",
            " 38%|███▊      | 23/60 [00:07<00:15,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2321215867996216\n",
            "Current test acc: 0.25%\n",
            "\n",
            "Epoch: 23\n",
            "======\n",
            "\n",
            "Current training loss: 0.9623458981513977\n",
            "Current training acc: 0.5756579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 388.27it/s]\n",
            " 40%|████      | 24/60 [00:08<00:15,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2425380945205688\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 24\n",
            "======\n",
            "\n",
            "Current training loss: 0.959081768989563\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 317.26it/s]\n",
            " 42%|████▏     | 25/60 [00:08<00:15,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2307257652282715\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 25\n",
            "======\n",
            "\n",
            "Current training loss: 0.9568836688995361\n",
            "Current training acc: 0.5789473652839661%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 376.07it/s]\n",
            " 43%|████▎     | 26/60 [00:09<00:14,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.282395839691162\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 26\n",
            "======\n",
            "\n",
            "Current training loss: 0.9638016223907471\n",
            "Current training acc: 0.5690789222717285%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 47%|████▋     | 36/76 [00:00<00:00, 357.68it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 304.96it/s]\n",
            " 45%|████▌     | 27/60 [00:09<00:14,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2540743350982666\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 27\n",
            "======\n",
            "\n",
            "Current training loss: 0.9587098360061646\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 360.86it/s]\n",
            " 47%|████▋     | 28/60 [00:09<00:14,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2796016931533813\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 28\n",
            "======\n",
            "\n",
            "Current training loss: 0.9546994566917419\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 32%|███▏      | 24/76 [00:00<00:00, 239.80it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 271.16it/s]\n",
            " 48%|████▊     | 29/60 [00:10<00:15,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2516459226608276\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 29\n",
            "======\n",
            "\n",
            "Current training loss: 0.953193187713623\n",
            "Current training acc: 0.5789473652839661%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 316.13it/s]\n",
            " 50%|█████     | 30/60 [00:11<00:14,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2750598192214966\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 30\n",
            "======\n",
            "\n",
            "Current training loss: 0.9523701667785645\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 348.80it/s]\n",
            " 52%|█████▏    | 31/60 [00:11<00:15,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.229172945022583\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 31\n",
            "======\n",
            "\n",
            "Current training loss: 0.9501519203186035\n",
            "Current training acc: 0.5888158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 386.74it/s]\n",
            " 53%|█████▎    | 32/60 [00:12<00:13,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2496956586837769\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 32\n",
            "======\n",
            "\n",
            "Current training loss: 0.9550756216049194\n",
            "Current training acc: 0.5822368264198303%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 38/76 [00:00<00:00, 377.33it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 302.20it/s]\n",
            " 55%|█████▌    | 33/60 [00:12<00:13,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2770421504974365\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 33\n",
            "======\n",
            "\n",
            "Current training loss: 0.9475957155227661\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 383.23it/s]\n",
            " 57%|█████▋    | 34/60 [00:13<00:12,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.251758337020874\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 34\n",
            "======\n",
            "\n",
            "Current training loss: 0.9447444081306458\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 370.12it/s]\n",
            " 58%|█████▊    | 35/60 [00:13<00:12,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2580451965332031\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 35\n",
            "======\n",
            "\n",
            "Current training loss: 0.9509104490280151\n",
            "Current training acc: 0.5789473652839661%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 49%|████▊     | 37/76 [00:00<00:00, 338.23it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 325.17it/s]\n",
            " 60%|██████    | 36/60 [00:14<00:12,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2423977851867676\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 36\n",
            "======\n",
            "\n",
            "Current training loss: 0.9464701414108276\n",
            "Current training acc: 0.5855262875556946%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 19/76 [00:00<00:00, 186.72it/s]\u001b[A\n",
            " 57%|█████▋    | 43/76 [00:00<00:00, 209.56it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 235.72it/s]\n",
            " 62%|██████▏   | 37/60 [00:14<00:12,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2529654502868652\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 37\n",
            "======\n",
            "\n",
            "Current training loss: 0.9444690346717834\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 41%|████      | 31/76 [00:00<00:00, 296.50it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 223.19it/s]\n",
            " 63%|██████▎   | 38/60 [00:15<00:12,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2759681940078735\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 38\n",
            "======\n",
            "\n",
            "Current training loss: 0.9426536560058594\n",
            "Current training acc: 0.5921052694320679%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 405.53it/s]\n",
            " 65%|██████▌   | 39/60 [00:15<00:10,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.297403335571289\n",
            "Current test acc: 0.19736842811107635%\n",
            "\n",
            "Epoch: 39\n",
            "======\n",
            "\n",
            "Current training loss: 0.9404643177986145\n",
            "Current training acc: 0.6118420958518982%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|█▉        | 15/76 [00:00<00:00, 149.64it/s]\u001b[A\n",
            " 39%|███▉      | 30/76 [00:00<00:00, 130.52it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 187.51it/s]\n",
            " 67%|██████▋   | 40/60 [00:16<00:11,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.263085961341858\n",
            "Current test acc: 0.28947368264198303%\n",
            "\n",
            "Epoch: 40\n",
            "======\n",
            "\n",
            "Current training loss: 0.9388298392295837\n",
            "Current training acc: 0.5986841917037964%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 322.11it/s]\n",
            " 68%|██████▊   | 41/60 [00:16<00:10,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2761811017990112\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 41\n",
            "======\n",
            "\n",
            "Current training loss: 0.9344448447227478\n",
            "Current training acc: 0.6052631735801697%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 34%|███▍      | 26/76 [00:00<00:00, 252.73it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 228.25it/s]\n",
            " 70%|███████   | 42/60 [00:17<00:09,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2501935958862305\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 42\n",
            "======\n",
            "\n",
            "Current training loss: 0.9341363310813904\n",
            "Current training acc: 0.6118420958518982%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 357.11it/s]\n",
            " 72%|███████▏  | 43/60 [00:17<00:08,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.1737260818481445\n",
            "Current test acc: 0.2763157784938812%\n",
            "\n",
            "Epoch: 43\n",
            "======\n",
            "\n",
            "Current training loss: 0.9307445883750916\n",
            "Current training acc: 0.6151315569877625%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|█▉        | 15/76 [00:00<00:00, 127.46it/s]\u001b[A\n",
            " 39%|███▉      | 30/76 [00:00<00:00, 138.47it/s]\u001b[A\n",
            " 61%|██████    | 46/76 [00:00<00:00, 147.17it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 163.07it/s]\n",
            " 73%|███████▎  | 44/60 [00:18<00:09,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2610692977905273\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n",
            "Epoch: 44\n",
            "======\n",
            "\n",
            "Current training loss: 0.9276437163352966\n",
            "Current training acc: 0.6118420958518982%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 18%|█▊        | 14/76 [00:00<00:00, 129.53it/s]\u001b[A\n",
            " 36%|███▌      | 27/76 [00:00<00:00, 120.70it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 201.36it/s]\n",
            " 75%|███████▌  | 45/60 [00:19<00:09,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.147242546081543\n",
            "Current test acc: 0.3947368562221527%\n",
            "\n",
            "Epoch: 45\n",
            "======\n",
            "\n",
            "Current training loss: 0.9302641153335571\n",
            "Current training acc: 0.6151315569877625%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 24%|██▎       | 18/76 [00:00<00:00, 167.61it/s]\u001b[A\n",
            " 46%|████▌     | 35/76 [00:00<00:00, 132.21it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 182.16it/s]\n",
            " 77%|███████▋  | 46/60 [00:19<00:08,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2606151103973389\n",
            "Current test acc: 0.21052631735801697%\n",
            "\n",
            "Epoch: 46\n",
            "======\n",
            "\n",
            "Current training loss: 0.9316221475601196\n",
            "Current training acc: 0.625%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 328.53it/s]\n",
            " 78%|███████▊  | 47/60 [00:20<00:07,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2509022951126099\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 47\n",
            "======\n",
            "\n",
            "Current training loss: 0.9310534596443176\n",
            "Current training acc: 0.6052631735801697%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 41%|████      | 31/76 [00:00<00:00, 308.03it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 243.34it/s]\n",
            " 80%|████████  | 48/60 [00:21<00:06,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.17892324924469\n",
            "Current test acc: 0.3552631437778473%\n",
            "\n",
            "Epoch: 48\n",
            "======\n",
            "\n",
            "Current training loss: 0.9210638999938965\n",
            "Current training acc: 0.6348684430122375%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 47%|████▋     | 36/76 [00:00<00:00, 354.26it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 320.50it/s]\n",
            " 82%|████████▏ | 49/60 [00:21<00:06,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.288888931274414\n",
            "Current test acc: 0.19736842811107635%\n",
            "\n",
            "Epoch: 49\n",
            "======\n",
            "\n",
            "Current training loss: 0.9213156700134277\n",
            "Current training acc: 0.625%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▍     | 34/76 [00:00<00:00, 335.59it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 199.42it/s]\n",
            " 83%|████████▎ | 50/60 [00:22<00:06,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2663367986679077\n",
            "Current test acc: 0.25%\n",
            "\n",
            "Epoch: 50\n",
            "======\n",
            "\n",
            "Current training loss: 0.9189607501029968\n",
            "Current training acc: 0.6217105388641357%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 275.98it/s]\n",
            " 85%|████████▌ | 51/60 [00:22<00:05,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2056355476379395\n",
            "Current test acc: 0.31578946113586426%\n",
            "\n",
            "Epoch: 51\n",
            "======\n",
            "\n",
            "Current training loss: 0.9135068655014038\n",
            "Current training acc: 0.6447368264198303%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 273.68it/s]\n",
            " 87%|████████▋ | 52/60 [00:23<00:04,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.271794319152832\n",
            "Current test acc: 0.18421052396297455%\n",
            "\n",
            "Epoch: 52\n",
            "======\n",
            "\n",
            "Current training loss: 0.9209580421447754\n",
            "Current training acc: 0.6348684430122375%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            " 49%|████▊     | 37/76 [00:00<00:00, 362.40it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 208.37it/s]\n",
            " 88%|████████▊ | 53/60 [00:23<00:03,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.3338534832000732\n",
            "Current test acc: 0.19736842811107635%\n",
            "\n",
            "Epoch: 53\n",
            "======\n",
            "\n",
            "Current training loss: 0.9141748547554016\n",
            "Current training acc: 0.6381579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 635.32it/s]\n",
            " 90%|█████████ | 54/60 [00:24<00:02,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2820111513137817\n",
            "Current test acc: 0.2368421107530594%\n",
            "\n",
            "Epoch: 54\n",
            "======\n",
            "\n",
            "Current training loss: 0.9120646119117737\n",
            "Current training acc: 0.6513158082962036%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 629.02it/s]\n",
            " 92%|█████████▏| 55/60 [00:24<00:02,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2402162551879883\n",
            "Current test acc: 0.28947368264198303%\n",
            "\n",
            "Epoch: 55\n",
            "======\n",
            "\n",
            "Current training loss: 0.9357267618179321\n",
            "Current training acc: 0.6315789222717285%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 597.04it/s]\n",
            " 93%|█████████▎| 56/60 [00:24<00:01,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2570174932479858\n",
            "Current test acc: 0.30263158679008484%\n",
            "\n",
            "Epoch: 56\n",
            "======\n",
            "\n",
            "Current training loss: 0.9298459887504578\n",
            "Current training acc: 0.6085526347160339%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 629.36it/s]\n",
            " 95%|█████████▌| 57/60 [00:24<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2637008428573608\n",
            "Current test acc: 0.28947368264198303%\n",
            "\n",
            "Epoch: 57\n",
            "======\n",
            "\n",
            "Current training loss: 0.9254694581031799\n",
            "Current training acc: 0.6381579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 615.23it/s]\n",
            " 97%|█████████▋| 58/60 [00:25<00:00,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.1366766691207886\n",
            "Current test acc: 0.3815789520740509%\n",
            "\n",
            "Epoch: 58\n",
            "======\n",
            "\n",
            "Current training loss: 0.9177716970443726\n",
            "Current training acc: 0.6381579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 637.72it/s]\n",
            " 98%|█████████▊| 59/60 [00:25<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.285136342048645\n",
            "Current test acc: 0.22368420660495758%\n",
            "\n",
            "Epoch: 59\n",
            "======\n",
            "\n",
            "Current training loss: 0.9125571250915527\n",
            "Current training acc: 0.6315789222717285%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/76 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 76/76 [00:00<00:00, 611.01it/s]\n",
            "100%|██████████| 60/60 [00:25<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current test loss: 1.2123827934265137\n",
            "Current test acc: 0.2631579041481018%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep_insight_evaluation = eval_model(deep_in_model,test_loader_tab2img,loss_fn_deep, acc_deep, device) # IT will create a dictionary with data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYGPBp7evItg",
        "outputId": "0be4848a-1748-4bcf-fe50-0f49e20feb7a"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:00<00:00, 670.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_insight_preds = torch.stack(model_deep_insight_evaluation[\"model_preds\"]).squeeze().argmax(dim=1) ## hmmm some weird issue, cause it's downloading "
      ],
      "metadata": {
        "id": "Pf_PuLzhvsdw"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_insight_acc = model_deep_insight_evaluation[\"model_acc\"]; deep_insight_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Z0hnjdw5Vt",
        "outputId": "da4226b6-54d5-435a-f544-f0fdfe237f32"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2631579041481018"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_insight_compare, deep_insight_score = check_score(main, deep_insight_preds.numpy()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evBNauEQ0Wts",
        "outputId": "421ff953-21f6-4ae8-a70c-28544d081f51"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_insight_score #Even though we are more then two times lower on accuracy, we are quite high in the terms of the betting odds summary. It seems to be very interesting..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWBZbj6l0xfB",
        "outputId": "a34a0854-f20d-4028-9caa-e5f7d2a9ff8e"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57.62"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's analyze this predictions a bit.\n",
        "deep_insight_compare.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ozv0WI6V1dVD",
        "outputId": "2d31aa03-663d-4665-d34c-10d05c60dd3d"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             FTR  predictions       AvgH       AvgA       AvgD  score_odds\n",
              "count  19.000000    19.000000  19.000000  19.000000  19.000000   19.000000\n",
              "mean    1.631579     1.631579   4.576316   3.607368   4.474211    3.032632\n",
              "std     0.495595     0.495595   3.708976   2.642461   0.972627    1.377396\n",
              "min     1.000000     1.000000   1.360000   1.260000   3.320000    1.260000\n",
              "25%     1.000000     1.000000   1.885000   1.425000   3.575000    1.425000\n",
              "50%     2.000000     2.000000   2.670000   2.610000   4.580000    3.520000\n",
              "75%     2.000000     2.000000   7.580000   4.360000   4.930000    3.760000\n",
              "max     2.000000     2.000000  12.830000   9.620000   6.450000    4.950000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad0aca43-3bd3-4f5b-b364-932efdbe3f08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTR</th>\n",
              "      <th>predictions</th>\n",
              "      <th>AvgH</th>\n",
              "      <th>AvgA</th>\n",
              "      <th>AvgD</th>\n",
              "      <th>score_odds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.631579</td>\n",
              "      <td>1.631579</td>\n",
              "      <td>4.576316</td>\n",
              "      <td>3.607368</td>\n",
              "      <td>4.474211</td>\n",
              "      <td>3.032632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.495595</td>\n",
              "      <td>0.495595</td>\n",
              "      <td>3.708976</td>\n",
              "      <td>2.642461</td>\n",
              "      <td>0.972627</td>\n",
              "      <td>1.377396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>1.260000</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>1.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.885000</td>\n",
              "      <td>1.425000</td>\n",
              "      <td>3.575000</td>\n",
              "      <td>1.425000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.670000</td>\n",
              "      <td>2.610000</td>\n",
              "      <td>4.580000</td>\n",
              "      <td>3.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.580000</td>\n",
              "      <td>4.360000</td>\n",
              "      <td>4.930000</td>\n",
              "      <td>3.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>12.830000</td>\n",
              "      <td>9.620000</td>\n",
              "      <td>6.450000</td>\n",
              "      <td>4.950000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad0aca43-3bd3-4f5b-b364-932efdbe3f08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad0aca43-3bd3-4f5b-b364-932efdbe3f08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad0aca43-3bd3-4f5b-b364-932efdbe3f08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_odds_per_bet_di = deep_insight_compare.describe().loc[\"mean\"][\"score_odds\"]"
      ],
      "metadata": {
        "id": "VCkyReNs2Bua"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Tab2Img / DeepInsight results\n",
        "I ran it a couple of times, but it looks completly random at this stage. But I'll give it a try anyway."
      ],
      "metadata": {
        "id": "09ECmlTM2DRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "The aim of this notebook was to compare four baseline models, and how far we are from beating the bookkeepers. Without tuning, with close to default hyperparams, we have the following output."
      ],
      "metadata": {
        "id": "oYUCrNGUbStX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_dict = {\"TabNet\":{\"score\":score_tabnet,\n",
        "                        \"acc\":tabnet_accuracy,\n",
        "                        \"avg_odds\":avg_odds_per_bet_tabnet},\n",
        "              \"XGB\":{\"score\":score_xgb,\n",
        "                        \"acc\":xgboost_acc_test,\n",
        "                     \"avg_odds\":avg_odds_per_bet_xgb},\n",
        "              \"RandomForest\":{\"score\":score_rf,\n",
        "                        \"acc\":rf_acc,\n",
        "                        \"avg_odds\":avg_odds_per_bet_rf},\n",
        "                \"DeepInsight\":{\"score\":deep_insight_score,\n",
        "                        \"acc\":deep_insight_acc,\n",
        "                        \"avg_odds\":avg_odds_per_bet_di},\n",
        "                \"TargetValues\":{\"score\":76,\n",
        "                        \"acc\":round(1/sum_of_odds*100, 4),\n",
        "                        \"avg_odds\":(163*1.16+129*1.78+3.37*88)/380}}\n",
        "\n",
        "\n",
        "compare_df = pd.DataFrame.from_dict(compare_dict).T ; compare_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WucwxDHzHi1K",
        "outputId": "2753be7b-2de6-4478-b139-564d92826df3"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              score        acc  avg_odds\n",
              "TabNet        92.46   0.592105  2.054667\n",
              "XGB           75.53   0.552632  1.798333\n",
              "RandomForest  73.40   0.539474  1.790244\n",
              "DeepInsight   57.62   0.263158  3.032632\n",
              "TargetValues  76.00  53.151900  1.882263"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-061240ad-5f84-4330-a0a2-e46d9d9cac14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>acc</th>\n",
              "      <th>avg_odds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TabNet</th>\n",
              "      <td>92.46</td>\n",
              "      <td>0.592105</td>\n",
              "      <td>2.054667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>75.53</td>\n",
              "      <td>0.552632</td>\n",
              "      <td>1.798333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>73.40</td>\n",
              "      <td>0.539474</td>\n",
              "      <td>1.790244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DeepInsight</th>\n",
              "      <td>57.62</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>3.032632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TargetValues</th>\n",
              "      <td>76.00</td>\n",
              "      <td>53.151900</td>\n",
              "      <td>1.882263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-061240ad-5f84-4330-a0a2-e46d9d9cac14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-061240ad-5f84-4330-a0a2-e46d9d9cac14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-061240ad-5f84-4330-a0a2-e46d9d9cac14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TabNet we may consider already working Proof of Concept\n",
        "With baseline TabNet params we are close to guessing 2 out of 3 games, so it's a very good start. But there is absolutely something worthy consideration in this DeepInsight approach. Maybe upscaling, maybe adding some layers, maybe some data manipulation and transormations... \n",
        "\n",
        "Nevertheless - it was all about understanding the baseline, and here we go - the baseline is already working Proof of Concept!"
      ],
      "metadata": {
        "id": "x5OICtifvrYF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKm1LAohN_vN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}